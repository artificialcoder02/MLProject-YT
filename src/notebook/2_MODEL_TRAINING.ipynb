{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Model Training"
      ],
      "metadata": {
        "id": "j8uf7z0qi7UZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##1.1 Import Data and Required Packages\n",
        "### Importing Pandas, Numpy, Matplotlib, Seaborn and Warings Library."
      ],
      "metadata": {
        "id": "IZVEOCZ9i99K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "# Modelling\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import warnings"
      ],
      "metadata": {
        "id": "F8N6ADOGjFJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import the CSV Data as Pandas DataFrame"
      ],
      "metadata": {
        "id": "AiqSEmjxjLly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data/stud.csv')"
      ],
      "metadata": {
        "id": "hDOL5Bb0jNsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Show Top 5 Records"
      ],
      "metadata": {
        "id": "Bbp7Fpx_jPFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "HllY-ed8jRJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Preparing X and Y variables"
      ],
      "metadata": {
        "id": "m71zuDFwjSss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['math_score'],axis=1)"
      ],
      "metadata": {
        "id": "UuY-oZBtjVOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "Ibc8tq8RjWdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['math_score']"
      ],
      "metadata": {
        "id": "wK8XzBlwjaSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "PXr2lRsvjbil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Column Transformer with 3 types of transformers\n",
        "num_features = X.select_dtypes(exclude=\"object\").columns\n",
        "cat_features = X.select_dtypes(include=\"object\").columns\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "numeric_transformer = StandardScaler()\n",
        "oh_transformer = OneHotEncoder()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    [\n",
        "        (\"OneHotEncoder\", oh_transformer, cat_features),\n",
        "         (\"StandardScaler\", numeric_transformer, num_features),        \n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "wciv_hkTjeeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = preprocessor.fit_transform(X)"
      ],
      "metadata": {
        "id": "8hN_-wSPjfOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "ED1bFtRSjgjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separate dataset into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "btvYM9HwjhtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "Create an Evaluate Function to give all metrics after model Training"
      ],
      "metadata": {
        "id": "FpicEUsyjkIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(true, predicted):\n",
        "    mae = mean_absolute_error(true, predicted)\n",
        "    mse = mean_squared_error(true, predicted)\n",
        "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
        "    r2_square = r2_score(true, predicted)\n",
        "    return mae, rmse, r2_square"
      ],
      "metadata": {
        "id": "gIrFES6Uji6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Lasso\": Lasso(),\n",
        "    \"Ridge\": Ridge(),\n",
        "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(),\n",
        "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
        "    \"XGBRegressor\": XGBRegressor(), \n",
        "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
        "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
        "}\n",
        "model_list = []\n",
        "r2_list =[]\n",
        "\n",
        "for i in range(len(list(models))):\n",
        "    model = list(models.values())[i]\n",
        "    model.fit(X_train, y_train) # Train model\n",
        "\n",
        "    # Make predictions\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    \n",
        "    # Evaluate Train and Test dataset\n",
        "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
        "\n",
        "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
        "\n",
        "    \n",
        "    print(list(models.keys())[i])\n",
        "    model_list.append(list(models.keys())[i])\n",
        "    \n",
        "    print('Model performance for Training set')\n",
        "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
        "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
        "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
        "\n",
        "    print('----------------------------------')\n",
        "    \n",
        "    print('Model performance for Test set')\n",
        "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
        "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
        "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
        "    r2_list.append(model_test_r2)\n",
        "    \n",
        "    print('='*35)\n",
        "    print('\\n')\n"
      ],
      "metadata": {
        "id": "ntXkbKw3jnxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Results"
      ],
      "metadata": {
        "id": "xTMXvCDJjsuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name', 'R2_Score']).sort_values(by=[\"R2_Score\"],ascending=False)"
      ],
      "metadata": {
        "id": "MZOlGkppjq7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear Regression"
      ],
      "metadata": {
        "id": "UxKSAl6-jwu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lin_model = LinearRegression(fit_intercept=True)\n",
        "lin_model = lin_model.fit(X_train, y_train)\n",
        "y_pred = lin_model.predict(X_test)\n",
        "score = r2_score(y_test, y_pred)*100\n",
        "print(\" Accuracy of the model is %.2f\" %score)"
      ],
      "metadata": {
        "id": "OFLVv7IYjyfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plot y_pred and y_test"
      ],
      "metadata": {
        "id": "BQR-dG7yj0m6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(y_test,y_pred);\n",
        "plt.xlabel('Actual');\n",
        "plt.ylabel('Predicted');"
      ],
      "metadata": {
        "id": "YvGzyLpLj2Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.regplot(x=y_test,y=y_pred,ci=None,color ='red');"
      ],
      "metadata": {
        "id": "hERkRQ8qj42a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Difference between Actual and Predicted Values"
      ],
      "metadata": {
        "id": "SlNGVWwUj6Ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df=pd.DataFrame({'Actual Value':y_test,'Predicted Value':y_pred,'Difference':y_test-y_pred})\n",
        "pred_df"
      ],
      "metadata": {
        "id": "1WfvLvGOj7Qt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}